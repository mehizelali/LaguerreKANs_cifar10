{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4e42d4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-31T18:58:55.916818Z",
     "iopub.status.busy": "2025-07-31T18:58:55.916516Z",
     "iopub.status.idle": "2025-07-31T18:58:57.373328Z",
     "shell.execute_reply": "2025-07-31T18:58:57.372526Z"
    },
    "papermill": {
     "duration": 1.461615,
     "end_time": "2025-07-31T18:58:57.374783",
     "exception": false,
     "start_time": "2025-07-31T18:58:55.913168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf9193ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T18:58:57.380111Z",
     "iopub.status.busy": "2025-07-31T18:58:57.379769Z",
     "iopub.status.idle": "2025-07-31T18:59:06.839626Z",
     "shell.execute_reply": "2025-07-31T18:59:06.838794Z"
    },
    "papermill": {
     "duration": 9.464059,
     "end_time": "2025-07-31T18:59:06.841246",
     "exception": false,
     "start_time": "2025-07-31T18:58:57.377187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "def laguerre_polynomials(x, degree):\n",
    "    \"\"\"\n",
    "    Compute the first `degree` Laguerre polynomials L_0(x), ..., L_{degree-1}(x).\n",
    "    x should be a tensor of shape [...], returns a tensor of shape [..., degree].\n",
    "    \"\"\"\n",
    "    L = [torch.ones_like(x), 1 - x]  # L_0, L_1\n",
    "\n",
    "    for n in range(2, degree):\n",
    "        Ln = ((2 * n - 1 - x) * L[-1] - (n - 1) * L[-2]) / n\n",
    "        L.append(Ln)\n",
    "\n",
    "    return torch.stack(L[:degree], dim=-1)  # [..., degree]\n",
    "\n",
    "class KANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, grid=3, use_resid=False, resid=nn.SiLU):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.grid = grid\n",
    "        self.use_resid = use_resid\n",
    "\n",
    "        self.laguerre_scale = nn.Parameter(torch.ones(input_dim))  # Learnable scale for each input dim\n",
    "\n",
    "        self.kan_proj = nn.Linear(input_dim * grid, output_dim)\n",
    "\n",
    "        if self.use_resid:\n",
    "            self.resid_act = resid()\n",
    "            self.resid_linear = nn.Linear(input_dim, output_dim)\n",
    "        else:\n",
    "            self.resid_act = None\n",
    "            self.resid_linear = None\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.kaiming_normal_(self.kan_proj.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.kan_proj.bias)\n",
    "        if self.use_resid:\n",
    "            nn.init.kaiming_normal_(self.resid_linear.weight, nonlinearity='linear')\n",
    "            nn.init.zeros_(self.resid_linear.bias)\n",
    "\n",
    "    def kan_transform(self, x):\n",
    "        # x: [B, L, D]\n",
    "        B, L, D = x.shape\n",
    "        x_scaled = x * self.laguerre_scale  # [B, L, D]\n",
    "        x_reshaped = x_scaled.view(B * L * D)\n",
    "        basis = laguerre_polynomials(x_reshaped, self.grid)  # [B*L*D, G]\n",
    "        basis = basis.view(B, L, D, self.grid)  # [B, L, D, G]\n",
    "        phi = basis.reshape(B, L, D * self.grid)\n",
    "        return self.kan_proj(phi)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.kan_transform(x)\n",
    "        if self.use_resid:\n",
    "            res = self.resid_linear(self.resid_act(x))\n",
    "            out = out + res\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a334ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T18:59:06.845904Z",
     "iopub.status.busy": "2025-07-31T18:59:06.845542Z",
     "iopub.status.idle": "2025-07-31T18:59:06.849941Z",
     "shell.execute_reply": "2025-07-31T18:59:06.849225Z"
    },
    "papermill": {
     "duration": 0.007834,
     "end_time": "2025-07-31T18:59:06.851094",
     "exception": false,
     "start_time": "2025-07-31T18:59:06.843260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_patches(x, patch_size):\n",
    "    B, C, H, W = x.shape\n",
    "    x = x.unfold(2, patch_size, patch_size).unfold(3, patch_size, patch_size)\n",
    "    x = x.permute(0, 2, 3, 1, 4, 5).contiguous()  # [B, num_patches_y, num_patches_x, C, pH, pW]\n",
    "    x = x.view(B, -1, C * patch_size * patch_size)  # [B, num_patches, patch_dim]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c06e9c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T18:59:06.855415Z",
     "iopub.status.busy": "2025-07-31T18:59:06.855170Z",
     "iopub.status.idle": "2025-07-31T18:59:06.862356Z",
     "shell.execute_reply": "2025-07-31T18:59:06.861671Z"
    },
    "papermill": {
     "duration": 0.010513,
     "end_time": "2025-07-31T18:59:06.863415",
     "exception": false,
     "start_time": "2025-07-31T18:59:06.852902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KANBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, grid=4, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.kan = KANLayer(input_dim, output_dim, grid=grid, use_resid=True)\n",
    "        self.norm = nn.LayerNorm(output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.res_connection = (\n",
    "            nn.Linear(input_dim, output_dim) if input_dim != output_dim else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.res_connection(x)\n",
    "        x = self.kan(x)\n",
    "        x = self.norm(x + res)  # Add residual and normalize\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class KANForCIFAR(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, grid=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.kan1 = KANBlock(input_dim=input_dim, output_dim=hidden_dim, grid=grid, dropout=dropout)\n",
    "        self.kan2 = KANBlock(input_dim=hidden_dim, output_dim=hidden_dim, grid=grid, dropout=dropout)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)  # Pool over patch tokens\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = image_to_patches(x, patch_size=4)  # [B, P, D]\n",
    "        x = self.kan1(x)                        # [B, P, H]\n",
    "        x = self.kan2(x)                        # [B, P, H]\n",
    "        x = x.permute(0, 2, 1)                  # [B, H, P]\n",
    "        x = self.pool(x).squeeze(-1)            # [B, H]\n",
    "        return self.fc(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ec7621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T18:59:06.867457Z",
     "iopub.status.busy": "2025-07-31T18:59:06.867214Z",
     "iopub.status.idle": "2025-07-31T18:59:06.875751Z",
     "shell.execute_reply": "2025-07-31T18:59:06.874957Z"
    },
    "papermill": {
     "duration": 0.011908,
     "end_time": "2025-07-31T18:59:06.876922",
     "exception": false,
     "start_time": "2025-07-31T18:59:06.865014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Hyperparameters\n",
    "    patch_size = 4\n",
    "    patch_dim = 3 * patch_size * patch_size\n",
    "    hidden_dim = 128\n",
    "    num_classes = 10\n",
    "    grid = 4\n",
    "    epochs = 100\n",
    "    batch_size = 128\n",
    "\n",
    "    model = KANForCIFAR(\n",
    "        input_dim=patch_dim,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_classes=num_classes,\n",
    "        grid=grid\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_data = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "    test_data = datasets.CIFAR10(root=\"./data\", train=False, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct_train = 0.0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            correct_train += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        train_acc = correct_train / len(train_loader.dataset)\n",
    "        avg_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation on test set\n",
    "        model.eval()\n",
    "        correct_test = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                logits = model(images)\n",
    "                correct_test += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        test_acc = correct_test / len(test_loader.dataset)\n",
    "\n",
    "        # Print both train and test accuracy\n",
    "        print(f\"Epoch {epoch+1:03d}: Loss = {avg_loss:.4f}, Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
    "\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ca26e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-31T18:59:06.880672Z",
     "iopub.status.busy": "2025-07-31T18:59:06.880453Z",
     "iopub.status.idle": "2025-07-31T19:14:00.023771Z",
     "shell.execute_reply": "2025-07-31T19:14:00.022875Z"
    },
    "papermill": {
     "duration": 893.146579,
     "end_time": "2025-07-31T19:14:00.025096",
     "exception": false,
     "start_time": "2025-07-31T18:59:06.878517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:11<00:00, 14.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: Loss = 1.9632, Train Acc = 0.2704, Test Acc = 0.3187\n",
      "Epoch 002: Loss = 1.7718, Train Acc = 0.3346, Test Acc = 0.3429\n",
      "Epoch 003: Loss = 1.7150, Train Acc = 0.3585, Test Acc = 0.3772\n",
      "Epoch 004: Loss = 1.6734, Train Acc = 0.3804, Test Acc = 0.3792\n",
      "Epoch 005: Loss = 1.6310, Train Acc = 0.4025, Test Acc = 0.4114\n",
      "Epoch 006: Loss = 1.5991, Train Acc = 0.4147, Test Acc = 0.4125\n",
      "Epoch 007: Loss = 1.5670, Train Acc = 0.4274, Test Acc = 0.4301\n",
      "Epoch 008: Loss = 1.5484, Train Acc = 0.4362, Test Acc = 0.4318\n",
      "Epoch 009: Loss = 1.5344, Train Acc = 0.4408, Test Acc = 0.4383\n",
      "Epoch 010: Loss = 1.5192, Train Acc = 0.4497, Test Acc = 0.4401\n",
      "Epoch 011: Loss = 1.5068, Train Acc = 0.4546, Test Acc = 0.4500\n",
      "Epoch 012: Loss = 1.5013, Train Acc = 0.4556, Test Acc = 0.4594\n",
      "Epoch 013: Loss = 1.4910, Train Acc = 0.4582, Test Acc = 0.4525\n",
      "Epoch 014: Loss = 1.4811, Train Acc = 0.4643, Test Acc = 0.4566\n",
      "Epoch 015: Loss = 1.4770, Train Acc = 0.4660, Test Acc = 0.4671\n",
      "Epoch 016: Loss = 1.4693, Train Acc = 0.4679, Test Acc = 0.4703\n",
      "Epoch 017: Loss = 1.4682, Train Acc = 0.4705, Test Acc = 0.4579\n",
      "Epoch 018: Loss = 1.4592, Train Acc = 0.4723, Test Acc = 0.4618\n",
      "Epoch 019: Loss = 1.4510, Train Acc = 0.4760, Test Acc = 0.4779\n",
      "Epoch 020: Loss = 1.4481, Train Acc = 0.4797, Test Acc = 0.4538\n",
      "Epoch 021: Loss = 1.4387, Train Acc = 0.4812, Test Acc = 0.4792\n",
      "Epoch 022: Loss = 1.4376, Train Acc = 0.4804, Test Acc = 0.4619\n",
      "Epoch 023: Loss = 1.4310, Train Acc = 0.4818, Test Acc = 0.4731\n",
      "Epoch 024: Loss = 1.4270, Train Acc = 0.4875, Test Acc = 0.4819\n",
      "Epoch 025: Loss = 1.4248, Train Acc = 0.4887, Test Acc = 0.4634\n",
      "Epoch 026: Loss = 1.4197, Train Acc = 0.4870, Test Acc = 0.4821\n",
      "Epoch 027: Loss = 1.4163, Train Acc = 0.4913, Test Acc = 0.4784\n",
      "Epoch 028: Loss = 1.4110, Train Acc = 0.4933, Test Acc = 0.4761\n",
      "Epoch 029: Loss = 1.4046, Train Acc = 0.4971, Test Acc = 0.4816\n",
      "Epoch 030: Loss = 1.4043, Train Acc = 0.4938, Test Acc = 0.4886\n",
      "Epoch 031: Loss = 1.4022, Train Acc = 0.4943, Test Acc = 0.4828\n",
      "Epoch 032: Loss = 1.3988, Train Acc = 0.4988, Test Acc = 0.4933\n",
      "Epoch 033: Loss = 1.3947, Train Acc = 0.4989, Test Acc = 0.4956\n",
      "Epoch 034: Loss = 1.3924, Train Acc = 0.4984, Test Acc = 0.4920\n",
      "Epoch 035: Loss = 1.3925, Train Acc = 0.5007, Test Acc = 0.4949\n",
      "Epoch 036: Loss = 1.3890, Train Acc = 0.5015, Test Acc = 0.4997\n",
      "Epoch 037: Loss = 1.3906, Train Acc = 0.5002, Test Acc = 0.4963\n",
      "Epoch 038: Loss = 1.3847, Train Acc = 0.5042, Test Acc = 0.4914\n",
      "Epoch 039: Loss = 1.3837, Train Acc = 0.5040, Test Acc = 0.4938\n",
      "Epoch 040: Loss = 1.3791, Train Acc = 0.5048, Test Acc = 0.4948\n",
      "Epoch 041: Loss = 1.3797, Train Acc = 0.5077, Test Acc = 0.4940\n",
      "Epoch 042: Loss = 1.3772, Train Acc = 0.5039, Test Acc = 0.4915\n",
      "Epoch 043: Loss = 1.3754, Train Acc = 0.5056, Test Acc = 0.4872\n",
      "Epoch 044: Loss = 1.3760, Train Acc = 0.5075, Test Acc = 0.4952\n",
      "Epoch 045: Loss = 1.3666, Train Acc = 0.5090, Test Acc = 0.5097\n",
      "Epoch 046: Loss = 1.3656, Train Acc = 0.5123, Test Acc = 0.4991\n",
      "Epoch 047: Loss = 1.3671, Train Acc = 0.5126, Test Acc = 0.4917\n",
      "Epoch 048: Loss = 1.3670, Train Acc = 0.5114, Test Acc = 0.4843\n",
      "Epoch 049: Loss = 1.3667, Train Acc = 0.5121, Test Acc = 0.5016\n",
      "Epoch 050: Loss = 1.3636, Train Acc = 0.5115, Test Acc = 0.4936\n",
      "Epoch 051: Loss = 1.3596, Train Acc = 0.5159, Test Acc = 0.4803\n",
      "Epoch 052: Loss = 1.3625, Train Acc = 0.5096, Test Acc = 0.5007\n",
      "Epoch 053: Loss = 1.3555, Train Acc = 0.5164, Test Acc = 0.5035\n",
      "Epoch 054: Loss = 1.3553, Train Acc = 0.5162, Test Acc = 0.5032\n",
      "Epoch 055: Loss = 1.3537, Train Acc = 0.5164, Test Acc = 0.4871\n",
      "Epoch 056: Loss = 1.3526, Train Acc = 0.5182, Test Acc = 0.5120\n",
      "Epoch 057: Loss = 1.3511, Train Acc = 0.5180, Test Acc = 0.5111\n",
      "Epoch 058: Loss = 1.3501, Train Acc = 0.5178, Test Acc = 0.5109\n",
      "Epoch 059: Loss = 1.3453, Train Acc = 0.5184, Test Acc = 0.5036\n",
      "Epoch 060: Loss = 1.3477, Train Acc = 0.5195, Test Acc = 0.5109\n",
      "Epoch 061: Loss = 1.3449, Train Acc = 0.5198, Test Acc = 0.5066\n",
      "Epoch 062: Loss = 1.3432, Train Acc = 0.5201, Test Acc = 0.5169\n",
      "Epoch 063: Loss = 1.3434, Train Acc = 0.5195, Test Acc = 0.5021\n",
      "Epoch 064: Loss = 1.3411, Train Acc = 0.5224, Test Acc = 0.5169\n",
      "Epoch 065: Loss = 1.3418, Train Acc = 0.5196, Test Acc = 0.5087\n",
      "Epoch 066: Loss = 1.3406, Train Acc = 0.5228, Test Acc = 0.5080\n",
      "Epoch 067: Loss = 1.3385, Train Acc = 0.5204, Test Acc = 0.5143\n",
      "Epoch 068: Loss = 1.3352, Train Acc = 0.5216, Test Acc = 0.5078\n",
      "Epoch 069: Loss = 1.3350, Train Acc = 0.5239, Test Acc = 0.5093\n",
      "Epoch 070: Loss = 1.3349, Train Acc = 0.5232, Test Acc = 0.5166\n",
      "Epoch 071: Loss = 1.3347, Train Acc = 0.5243, Test Acc = 0.5013\n",
      "Epoch 072: Loss = 1.3340, Train Acc = 0.5207, Test Acc = 0.5125\n",
      "Epoch 073: Loss = 1.3328, Train Acc = 0.5235, Test Acc = 0.5020\n",
      "Epoch 074: Loss = 1.3300, Train Acc = 0.5249, Test Acc = 0.5144\n",
      "Epoch 075: Loss = 1.3256, Train Acc = 0.5277, Test Acc = 0.5078\n",
      "Epoch 076: Loss = 1.3277, Train Acc = 0.5255, Test Acc = 0.5058\n",
      "Epoch 077: Loss = 1.3242, Train Acc = 0.5289, Test Acc = 0.5100\n",
      "Epoch 078: Loss = 1.3276, Train Acc = 0.5243, Test Acc = 0.5078\n",
      "Epoch 079: Loss = 1.3257, Train Acc = 0.5282, Test Acc = 0.5156\n",
      "Epoch 080: Loss = 1.3228, Train Acc = 0.5313, Test Acc = 0.5113\n",
      "Epoch 081: Loss = 1.3206, Train Acc = 0.5304, Test Acc = 0.5126\n",
      "Epoch 082: Loss = 1.3198, Train Acc = 0.5285, Test Acc = 0.5087\n",
      "Epoch 083: Loss = 1.3221, Train Acc = 0.5259, Test Acc = 0.4975\n",
      "Epoch 084: Loss = 1.3254, Train Acc = 0.5278, Test Acc = 0.5159\n",
      "Epoch 085: Loss = 1.3201, Train Acc = 0.5294, Test Acc = 0.5190\n",
      "Epoch 086: Loss = 1.3170, Train Acc = 0.5317, Test Acc = 0.4907\n",
      "Epoch 087: Loss = 1.3146, Train Acc = 0.5315, Test Acc = 0.5134\n",
      "Epoch 088: Loss = 1.3140, Train Acc = 0.5320, Test Acc = 0.5187\n",
      "Epoch 089: Loss = 1.3146, Train Acc = 0.5309, Test Acc = 0.5144\n",
      "Epoch 090: Loss = 1.3145, Train Acc = 0.5319, Test Acc = 0.5161\n",
      "Epoch 091: Loss = 1.3138, Train Acc = 0.5307, Test Acc = 0.5134\n",
      "Epoch 092: Loss = 1.3132, Train Acc = 0.5311, Test Acc = 0.5006\n",
      "Epoch 093: Loss = 1.3120, Train Acc = 0.5313, Test Acc = 0.5158\n",
      "Epoch 094: Loss = 1.3143, Train Acc = 0.5322, Test Acc = 0.5203\n",
      "Epoch 095: Loss = 1.3107, Train Acc = 0.5346, Test Acc = 0.5077\n",
      "Epoch 096: Loss = 1.3121, Train Acc = 0.5321, Test Acc = 0.5263\n",
      "Epoch 097: Loss = 1.3069, Train Acc = 0.5328, Test Acc = 0.5154\n",
      "Epoch 098: Loss = 1.3064, Train Acc = 0.5326, Test Acc = 0.4995\n",
      "Epoch 099: Loss = 1.3048, Train Acc = 0.5322, Test Acc = 0.5130\n",
      "Epoch 100: Loss = 1.3054, Train Acc = 0.5341, Test Acc = 0.5259\n"
     ]
    }
   ],
   "source": [
    "model = train()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 910.132203,
   "end_time": "2025-07-31T19:14:01.553429",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-31T18:58:51.421226",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
